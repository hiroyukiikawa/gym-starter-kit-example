# エージェント開発 (基本編)

まずは、基本的なエージェントを作成していきます。

## GymKitAgent

Gym Starter Kitでは、OpenAI Gymでのエージェントとしての基本実装として、GymKitAgentクラスを提供しています。
GymKitAgentをオーバーライドすることで処理を実装することができます。

## RandomAgent

まずは、シンプルにランダムな行動(action)を環境に返すエージェントを作ってみましょう。
ソースコードの基本的な雛形をagent/random\_agent.pyに用意してあります。

actメソッドの引数として、環境から観測結果(observation)が渡されます。
戻り値として、行動(action)を返却することで、環境でその行動が行われます。

RandomAgentで以下の値を返して、ランダムな行動を取るようにしてみましょう。

    return self.env.action_space.sample()

### 実行

Gym Starter Kitはエージェントを実行するためにgym-startコマンドを適用しています。
RandomAgentは以下のコマンドで実行することができます。

    $ gym-start --agent agent.RandomAgent

デフォルトの環境はCartPole-v0が利用されています。
これはカート上にある棒が倒れないようにカートを前後させる単純なゲームです。
実行すると、CartPoleのウィンドウが開き、コンソール上にはログメッセージが表示されます。
デフォルトではエピソードを10回実行しますが、ランダムな行動を取っているので、すぐに終了します。

### 環境に関する情報

gym-startコマンドを実行すると、INFOレベルでログが出力されます。
観測結果と行動について、どのような値を扱うかのログも出力されます。

    [2017-01-02 22:19:35,833] Observation Space: Box(4,)
    [2017-01-02 22:19:35,834] Action Space: Discrete(2)

CartPoleでは観測結果が4属性で、行動は2値の値を返却するのがログによりわかります。
この情報はゲームにより異なるので、別のゲームを実行する際にこの情報により、扱うべきデータ構造を確認することができます。
また、実際にどのような値が観測されているかはgym-startコマンドに-vオプションを指定することで確認することができます。

    $ gym-start --agent agent.RandomAgent -v

